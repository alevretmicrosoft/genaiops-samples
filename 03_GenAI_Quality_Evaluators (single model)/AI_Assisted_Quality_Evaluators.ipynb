{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-ai-evaluation\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with RelevanceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The response is accurate and directly answers the query, providing all necessary information.'}\n",
      "{'coherence': 4.0, 'gpt_coherence': 4.0, 'coherence_reason': 'The response is coherent because it directly and correctly answers the query without any unnecessary information or confusion.'}\n",
      "{'fluency': 1.0, 'gpt_fluency': 1.0, 'fluency_reason': 'The input Data should get a Score of 1 because it shows minimal command of the language, with no grammatical structure or coherent message.'}\n",
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The response accurately and completely answers the query using information from the context, without introducing any errors or unrelated details.'}\n",
      "{'response_length': 13}\n",
      "{'contains_blocked_word': True}\n",
      "{'helpfulness': 1.0, 'helpfulness_reason': 'The RESPONSE is entirely unhelpful as it does not address the philosophical nature of the QUERY or relate to the CONTEXT. It provides a humorous but irrelevant answer.'}\n",
      "{'json_schema': 0.5, 'json_schema_reason': 'The JSON output is mostly correct but contains errors in the \"issueDate\" and \"dueDate\" fields, which are required to be strings in date-time format but are `None` instead.'}\n",
      "{'json_schema': 0.5, 'json_schema_reason': 'The JSON output is mostly correct but contains errors in the \"issueDate\" and \"dueDate\" fields, which are required to be date-time strings but are provided as `None`. This results in partial compliance with the schema.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Configure the AOAI model that will be used for evaluation (AI-as-a-judge)\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "}\n",
    "\n",
    "# Initialize the Relevance evaluator\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "\n",
    "# Evaluate a single query-response pair\n",
    "result = relevance_evaluator(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with CoherenceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator\n",
    "\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "\n",
    "result = coherence_evaluator(\n",
    "    query=\"What's the capital of France?\", \n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with FluencyEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import FluencyEvaluator\n",
    "\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "\n",
    "result = fluency_evaluator(\n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "\n",
    "result = groundedness_evaluator(\n",
    "    query=\"Who discovered penicillin?\",\n",
    "    context=\"Alexander Fleming discovered penicillin in 1928 while working at St. Mary's Hospital in London.\",\n",
    "    response=\"Alexander Fleming discovered penicillin in 1928.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code-based evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluator function to calculate response length\n",
    "def response_length_evaluator(response, **kwargs):\n",
    "    return {\"response_length\": len(response)}\n",
    "\n",
    "# Example usage\n",
    "result = response_length_evaluator(response=\"Hello, world!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class-based evaluator to check for blocked words\n",
    "class BlocklistEvaluator:\n",
    "    def __init__(self, blocklist):\n",
    "        self.blocklist = blocklist\n",
    "\n",
    "    def __call__(self, *, response: str, **kwargs):\n",
    "        contains_blocked_word = any(word in response for word in self.blocklist)\n",
    "        return {\"contains_blocked_word\": contains_blocked_word}\n",
    "    \n",
    "# Example usage\n",
    "blocklist_evaluator = BlocklistEvaluator(blocklist=[\"bad\", \"evil\", \"worst\"])\n",
    "result = blocklist_evaluator(response=\"This is the worst response ever!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt-based evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpfulness evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpfulness import HelpfulnessEvaluator\n",
    "\n",
    "helpfulness_evaluator = HelpfulnessEvaluator(model_config)\n",
    "\n",
    "helpfulness_score = helpfulness_evaluator(\n",
    "    query=\"What's the meaning of life?\", \n",
    "    context=\"Arthur Schopenhauer was the first to explicitly ask the question, in an essay entitled 'Character'.\", \n",
    "    response=\"The answer is 42.\"\n",
    ")\n",
    "print(helpfulness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON accuracy evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'json_schema': 0.5, 'json_schema_reason': 'The JSON output is mostly compliant with the schema, but it is missing the required \"companyName\" field in the \"companyInfo\" object. This omission prevents full compliance with the schema.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json_schema import JSONSchemaEvaluator\n",
    "\n",
    "# Load jsons/example.jsonl file here\n",
    "example_json_schema = json.load(open('jsons/example_schema.json', 'r'))\n",
    "\n",
    "# Example JSON object\n",
    "sample_json_data = json.load(open('jsons/poor_output.json', 'r'))\n",
    "\n",
    "json_schema_evaluator = JSONSchemaEvaluator(model_config)\n",
    "json_schema_score = json_schema_evaluator(json_output=sample_json_data, schema=example_json_schema)\n",
    "print(json_schema_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.ai.evaluation import evaluate\n",
    "from pprint import pprint\n",
    "from model_endpoint import ModelEndpoint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"RG_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Define your evaluators\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "\n",
    "# Evaluate the dataset\n",
    "result = evaluate(\n",
    "    data=\"evaluation_dataset.jsonl\",\n",
    "    target=ModelEndpoint(model_config),\n",
    "    evaluators={\n",
    "        # Performance and quality evaluators (AI-assisted)\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        # Custom evaluators (code and prompt based)\n",
    "        \"helpfulness\": helpfulness_evaluator,\n",
    "    },\n",
    "    evaluator_config={\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"coherence\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"helpfulness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "    },\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    output_path=\"./evaluation_results.json\",\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>outputs.response</th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.relevance.relevance</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.relevance.relevance_reason</th>\n",
       "      <th>outputs.coherence.coherence</th>\n",
       "      <th>outputs.coherence.gpt_coherence</th>\n",
       "      <th>outputs.coherence.coherence_reason</th>\n",
       "      <th>outputs.fluency.fluency</th>\n",
       "      <th>outputs.fluency.gpt_fluency</th>\n",
       "      <th>outputs.fluency.fluency_reason</th>\n",
       "      <th>outputs.groundedness.groundedness</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>outputs.groundedness.groundedness_reason</th>\n",
       "      <th>outputs.helpfulness.helpfulness</th>\n",
       "      <th>outputs.helpfulness.helpfulness_reason</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>World War I began on July 28, 1914, when Austr...</td>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>It involved multiple countries and lasted unti...</td>\n",
       "      <td>World War I</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is not only accurate and complete...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE demonstrates proficient fluency w...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The first person to walk on the moon was Neil ...</td>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The event occurred during the Apollo 11 missio...</td>\n",
       "      <td>Neil Armstrong</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is coherent and directly addresse...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is well-structured, grammatically...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>The year 1776 is highly significant in America...</td>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>A key document was signed declaring independen...</td>\n",
       "      <td>The Declaration of Independence</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is well-articulated with good con...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>The Berlin Wall fell in 1989, symbolizing the ...</td>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>It divided a German city into East and West.</td>\n",
       "      <td>The Berlin Wall</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent as it directly and cl...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE is clear and grammatically correc...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The ancient city buried by the eruption of Mou...</td>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The city's ruins were rediscovered in the 18th...</td>\n",
       "      <td>Pompeii</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is accurate, complete, and provid...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is well-articulated, with correct...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE accurately and completely answers...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE accurately and completely answers...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>During World War II, the British Prime Ministe...</td>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>He is famous for his leadership and speeches, ...</td>\n",
       "      <td>Winston Churchill</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent, directly answers the...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response demonstrates proficient fluency w...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully grounded in the context ...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>The ship that sank on its maiden voyage in 191...</td>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>It was deemed 'unsinkable' before it hit an ic...</td>\n",
       "      <td>RMS Titanic</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is accurate and complete, directl...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and directly answers ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The response is clear and grammatically correc...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>Genghis Khan was the founder and ruler of the ...</td>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>This empire became the largest contiguous land...</td>\n",
       "      <td>The Mongol Empire</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response not only accurately and completel...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE demonstrates proficient fluency w...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it directly a...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The primary cause of the American Civil War wa...</td>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The conflict between the Northern and Southern...</td>\n",
       "      <td>Slavery</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is well-articulated, with a good ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely address...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>The Great Pyramid of Giza was the ancient wond...</td>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>It is the only one of the Seven Wonders of the...</td>\n",
       "      <td>The Great Pyramid of Giza</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE demonstrates proficient fluency w...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       outputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                    outputs.response  \\\n",
       "0  World War I began on July 28, 1914, when Austr...   \n",
       "1  The first person to walk on the moon was Neil ...   \n",
       "2  The year 1776 is highly significant in America...   \n",
       "3  The Berlin Wall fell in 1989, symbolizing the ...   \n",
       "4  The ancient city buried by the eruption of Mou...   \n",
       "5  During World War II, the British Prime Ministe...   \n",
       "6  The ship that sank on its maiden voyage in 191...   \n",
       "7  Genghis Khan was the founder and ruler of the ...   \n",
       "8  The primary cause of the American Civil War wa...   \n",
       "9  The Great Pyramid of Giza was the ancient wond...   \n",
       "\n",
       "                                        inputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  It involved multiple countries and lasted unti...   \n",
       "1  The event occurred during the Apollo 11 missio...   \n",
       "2  A key document was signed declaring independen...   \n",
       "3       It divided a German city into East and West.   \n",
       "4  The city's ruins were rediscovered in the 18th...   \n",
       "5  He is famous for his leadership and speeches, ...   \n",
       "6  It was deemed 'unsinkable' before it hit an ic...   \n",
       "7  This empire became the largest contiguous land...   \n",
       "8  The conflict between the Northern and Southern...   \n",
       "9  It is the only one of the Seven Wonders of the...   \n",
       "\n",
       "               inputs.ground_truth  outputs.relevance.relevance  \\\n",
       "0                      World War I                            5   \n",
       "1                   Neil Armstrong                            5   \n",
       "2  The Declaration of Independence                            5   \n",
       "3                  The Berlin Wall                            4   \n",
       "4                          Pompeii                            5   \n",
       "5                Winston Churchill                            5   \n",
       "6                      RMS Titanic                            4   \n",
       "7                The Mongol Empire                            5   \n",
       "8                          Slavery                            5   \n",
       "9        The Great Pyramid of Giza                            5   \n",
       "\n",
       "   outputs.relevance.gpt_relevance  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                4   \n",
       "4                                5   \n",
       "5                                5   \n",
       "6                                4   \n",
       "7                                5   \n",
       "8                                5   \n",
       "9                                5   \n",
       "\n",
       "                  outputs.relevance.relevance_reason  \\\n",
       "0  The response is not only accurate and complete...   \n",
       "1  The response accurately and completely answers...   \n",
       "2  The response fully addresses the query with ac...   \n",
       "3  The RESPONSE fully addresses the QUERY with ac...   \n",
       "4  The response is accurate, complete, and provid...   \n",
       "5  The response fully addresses the query with ac...   \n",
       "6  The response is accurate and complete, directl...   \n",
       "7  The response not only accurately and completel...   \n",
       "8  The response fully addresses the query with ac...   \n",
       "9  The response fully addresses the query with ac...   \n",
       "\n",
       "   outputs.coherence.coherence  outputs.coherence.gpt_coherence  \\\n",
       "0                            4                                4   \n",
       "1                            4                                4   \n",
       "2                            4                                4   \n",
       "3                            4                                4   \n",
       "4                            4                                4   \n",
       "5                            4                                4   \n",
       "6                            4                                4   \n",
       "7                            4                                4   \n",
       "8                            4                                4   \n",
       "9                            4                                4   \n",
       "\n",
       "                  outputs.coherence.coherence_reason  outputs.fluency.fluency  \\\n",
       "0  The RESPONSE is coherent and effectively addre...                        4   \n",
       "1  The response is coherent and directly addresse...                        4   \n",
       "2  The RESPONSE is coherent and effectively addre...                        4   \n",
       "3  The RESPONSE is coherent as it directly and cl...                        3   \n",
       "4  The RESPONSE is coherent and effectively addre...                        4   \n",
       "5  The RESPONSE is coherent, directly answers the...                        4   \n",
       "6  The RESPONSE is coherent and directly answers ...                        3   \n",
       "7  The RESPONSE is coherent and effectively addre...                        4   \n",
       "8  The RESPONSE is coherent and effectively addre...                        4   \n",
       "9  The RESPONSE is coherent and effectively addre...                        4   \n",
       "\n",
       "   outputs.fluency.gpt_fluency  \\\n",
       "0                            4   \n",
       "1                            4   \n",
       "2                            4   \n",
       "3                            3   \n",
       "4                            4   \n",
       "5                            4   \n",
       "6                            3   \n",
       "7                            4   \n",
       "8                            4   \n",
       "9                            4   \n",
       "\n",
       "                      outputs.fluency.fluency_reason  \\\n",
       "0  The RESPONSE demonstrates proficient fluency w...   \n",
       "1  The RESPONSE is well-structured, grammatically...   \n",
       "2  The RESPONSE is well-articulated with good con...   \n",
       "3  The RESPONSE is clear and grammatically correc...   \n",
       "4  The response is well-articulated, with correct...   \n",
       "5  The response demonstrates proficient fluency w...   \n",
       "6  The response is clear and grammatically correc...   \n",
       "7  The RESPONSE demonstrates proficient fluency w...   \n",
       "8  The RESPONSE is well-articulated, with a good ...   \n",
       "9  The RESPONSE demonstrates proficient fluency w...   \n",
       "\n",
       "   outputs.groundedness.groundedness  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                  5                                      5   \n",
       "1                                  5                                      5   \n",
       "2                                  5                                      5   \n",
       "3                                  5                                      5   \n",
       "4                                  5                                      5   \n",
       "5                                  5                                      5   \n",
       "6                                  5                                      5   \n",
       "7                                  5                                      5   \n",
       "8                                  5                                      5   \n",
       "9                                  5                                      5   \n",
       "\n",
       "            outputs.groundedness.groundedness_reason  \\\n",
       "0  The response accurately and completely answers...   \n",
       "1  The response is fully correct and complete, di...   \n",
       "2  The RESPONSE is fully correct and complete, di...   \n",
       "3  The response accurately and completely answers...   \n",
       "4  The RESPONSE accurately and completely answers...   \n",
       "5  The response is fully grounded in the context ...   \n",
       "6  The response is fully correct and complete, di...   \n",
       "7  The response is fully correct and complete, di...   \n",
       "8  The response accurately and completely address...   \n",
       "9  The response is fully correct and complete, di...   \n",
       "\n",
       "   outputs.helpfulness.helpfulness  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                5   \n",
       "4                                5   \n",
       "5                                5   \n",
       "6                                5   \n",
       "7                                5   \n",
       "8                                5   \n",
       "9                                5   \n",
       "\n",
       "              outputs.helpfulness.helpfulness_reason  line_number  \n",
       "0  The RESPONSE is fully helpful as it accurately...            0  \n",
       "1  The RESPONSE is entirely helpful as it accurat...            1  \n",
       "2  The RESPONSE is fully helpful as it accurately...            2  \n",
       "3  The RESPONSE is fully helpful as it accurately...            3  \n",
       "4  The RESPONSE accurately and completely answers...            4  \n",
       "5  The RESPONSE is entirely helpful as it accurat...            5  \n",
       "6  The RESPONSE is fully helpful as it accurately...            6  \n",
       "7  The RESPONSE is fully helpful as it directly a...            7  \n",
       "8  The RESPONSE is entirely helpful as it accurat...            8  \n",
       "9  The RESPONSE is fully helpful as it accurately...            9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result[\"rows\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
