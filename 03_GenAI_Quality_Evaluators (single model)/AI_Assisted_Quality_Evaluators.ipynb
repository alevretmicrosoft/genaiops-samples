{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-evaluation\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with RelevanceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The response is accurate and directly answers the query, providing all necessary information.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Configure the AOAI model\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "}\n",
    "\n",
    "# Initialize the Relevance evaluator\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "\n",
    "# Evaluate a single query-response pair\n",
    "result = relevance_evaluator(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with CoherenceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coherence': 4.0, 'gpt_coherence': 4.0, 'coherence_reason': 'The response is coherent because it directly and correctly answers the query without any unnecessary information or confusion.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator\n",
    "\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "\n",
    "result = coherence_evaluator(\n",
    "    query=\"What's the capital of France?\", \n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with FluencyEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fluency': 1.0, 'gpt_fluency': 1.0, 'fluency_reason': 'The RESPONSE is a single word and does not demonstrate any fluency in terms of sentence structure, grammar, or vocabulary. It is largely incomprehensible as it does not convey any meaningful message.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import FluencyEvaluator\n",
    "\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "\n",
    "result = fluency_evaluator(\n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The response accurately and completely answers the query using information from the context, without introducing any errors or irrelevant details.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "\n",
    "result = groundedness_evaluator(\n",
    "    query=\"Who discovered penicillin?\",\n",
    "    context=\"Alexander Fleming discovered penicillin in 1928 while working at St. Mary's Hospital in London.\",\n",
    "    response=\"Alexander Fleming discovered penicillin in 1928.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code-based evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response_length': 13}\n"
     ]
    }
   ],
   "source": [
    "# Custom evaluator function to calculate response length\n",
    "def response_length_evaluator(response, **kwargs):\n",
    "    return {\"response_length\": len(response)}\n",
    "\n",
    "# Example usage\n",
    "result = response_length_evaluator(response=\"Hello, world!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains_blocked_word': True}\n"
     ]
    }
   ],
   "source": [
    "# Custom class-based evaluator to check for blocked words\n",
    "class BlocklistEvaluator:\n",
    "    def __init__(self, blocklist):\n",
    "        self.blocklist = blocklist\n",
    "\n",
    "    def __call__(self, *, response: str, **kwargs):\n",
    "        contains_blocked_word = any(word in response for word in self.blocklist)\n",
    "        return {\"contains_blocked_word\": contains_blocked_word}\n",
    "    \n",
    "# Example usage\n",
    "blocklist_evaluator = BlocklistEvaluator(blocklist=[\"bad\", \"evil\", \"worst\"])\n",
    "result = blocklist_evaluator(response=\"This is the worst response ever!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt-based evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpfulness evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'helpfulness': 1.0, 'helpfulness_reason': 'The RESPONSE is entirely unhelpful as it does not address the philosophical nature of the QUERY or provide any meaningful information related to the CONTEXT.'}\n"
     ]
    }
   ],
   "source": [
    "from helpfulness import HelpfulnessEvaluator\n",
    "\n",
    "helpfulness_evaluator = HelpfulnessEvaluator(model_config)\n",
    "\n",
    "helpfulness_score = helpfulness_evaluator(\n",
    "    query=\"What's the meaning of life?\", \n",
    "    context=\"Arthur Schopenhauer was the first to explicitly ask the question, in an essay entitled 'Character'.\", \n",
    "    response=\"The answer is 42.\"\n",
    ")\n",
    "print(helpfulness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON accuracy evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'json_accuracy': 0.5, 'json_accuracy_reason': 'The JSON output is mostly correct but is missing the required \"companyName\" field in the \"companyInfo\" object, which affects its completeness according to the schema.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json_accuracy import JSONAccuracyEvaluator\n",
    "\n",
    "# Load jsons/example.jsonl file here\n",
    "example_json_schema = json.load(open('jsons/example_schema.json', 'r'))\n",
    "\n",
    "# Example JSON object\n",
    "sample_json_data = json.load(open('jsons/poor_output.json', 'r'))\n",
    "\n",
    "accuracy_evaluator = JSONAccuracyEvaluator(model_config)\n",
    "accuracy_score = accuracy_evaluator(json_output=sample_json_data, schema=example_json_schema)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.ai.evaluation import evaluate\n",
    "from pprint import pprint\n",
    "from model_endpoint import ModelEndpoint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"RG_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Define your evaluators\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "\n",
    "# Evaluate the dataset\n",
    "result = evaluate(\n",
    "    data=\"evaluation_dataset.jsonl\",\n",
    "    target=ModelEndpoint(model_config),\n",
    "    evaluators={\n",
    "        # Performance and quality evaluators (AI-assisted)\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        # Custom evaluators (code and prompt based)\n",
    "        \"helpfulness\": helpfulness_evaluator,\n",
    "    },\n",
    "    evaluator_config={\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"coherence\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"helpfulness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "    },\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    output_path=\"./evaluation_results.json\",\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>outputs.response</th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.relevance.relevance</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.relevance.relevance_reason</th>\n",
       "      <th>outputs.coherence.coherence</th>\n",
       "      <th>outputs.coherence.gpt_coherence</th>\n",
       "      <th>outputs.coherence.coherence_reason</th>\n",
       "      <th>outputs.fluency.fluency</th>\n",
       "      <th>outputs.fluency.gpt_fluency</th>\n",
       "      <th>outputs.fluency.fluency_reason</th>\n",
       "      <th>outputs.groundedness.groundedness</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>outputs.groundedness.groundedness_reason</th>\n",
       "      <th>outputs.helpfulness.helpfulness</th>\n",
       "      <th>outputs.helpfulness.helpfulness_reason</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>World War I began on July 28, 1914, when Austr...</td>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>It involved multiple countries and lasted unti...</td>\n",
       "      <td>World War I</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely address...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE demonstrates proficient fluency w...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately identifies the event a...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The first person to walk on the moon was Neil ...</td>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The event occurred during the Apollo 11 missio...</td>\n",
       "      <td>Neil Armstrong</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is coherent and directly addresse...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is well-articulated, with good co...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>The year 1776 is highly significant in America...</td>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>A key document was signed declaring independen...</td>\n",
       "      <td>The Declaration of Independence</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE should receive a high score becau...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it fully a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>The Berlin Wall fell in 1989, symbolizing the ...</td>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>It divided a German city into East and West.</td>\n",
       "      <td>The Berlin Wall</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent as it directly answer...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE is clear and coherent with correc...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The ancient city buried by the eruption of Mou...</td>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The city's ruins were rediscovered in the 18th...</td>\n",
       "      <td>Pompeii</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE not only answers the QUERY accura...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE is clear and coherent, with corre...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully correct and complete in ...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>During World War II, the British Prime Ministe...</td>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>He is famous for his leadership and speeches, ...</td>\n",
       "      <td>Winston Churchill</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent, directly answers the...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is well-articulated with good con...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>The ship that sank on its maiden voyage in 191...</td>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>It was deemed 'unsinkable' before it hit an ic...</td>\n",
       "      <td>RMS Titanic</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE accurately and completely answers...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is coherent because it directly a...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The response is clear and grammatically correc...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>Genghis Khan ruled the Mongol Empire. He found...</td>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>This empire became the largest contiguous land...</td>\n",
       "      <td>The Mongol Empire</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response not only accurately and completel...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is coherent and effectively addre...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE is clear and coherent, with corre...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The primary cause of the American Civil War wa...</td>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The conflict between the Northern and Southern...</td>\n",
       "      <td>Slavery</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE should receive a high score becau...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully grounded in the context,...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>The ancient wonder located in Egypt that serve...</td>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>It is the only one of the Seven Wonders of the...</td>\n",
       "      <td>The Great Pyramid of Giza</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is coherent and effectively addre...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is well-articulated with correct ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       outputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                    outputs.response  \\\n",
       "0  World War I began on July 28, 1914, when Austr...   \n",
       "1  The first person to walk on the moon was Neil ...   \n",
       "2  The year 1776 is highly significant in America...   \n",
       "3  The Berlin Wall fell in 1989, symbolizing the ...   \n",
       "4  The ancient city buried by the eruption of Mou...   \n",
       "5  During World War II, the British Prime Ministe...   \n",
       "6  The ship that sank on its maiden voyage in 191...   \n",
       "7  Genghis Khan ruled the Mongol Empire. He found...   \n",
       "8  The primary cause of the American Civil War wa...   \n",
       "9  The ancient wonder located in Egypt that serve...   \n",
       "\n",
       "                                        inputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  It involved multiple countries and lasted unti...   \n",
       "1  The event occurred during the Apollo 11 missio...   \n",
       "2  A key document was signed declaring independen...   \n",
       "3       It divided a German city into East and West.   \n",
       "4  The city's ruins were rediscovered in the 18th...   \n",
       "5  He is famous for his leadership and speeches, ...   \n",
       "6  It was deemed 'unsinkable' before it hit an ic...   \n",
       "7  This empire became the largest contiguous land...   \n",
       "8  The conflict between the Northern and Southern...   \n",
       "9  It is the only one of the Seven Wonders of the...   \n",
       "\n",
       "               inputs.ground_truth  outputs.relevance.relevance  \\\n",
       "0                      World War I                            5   \n",
       "1                   Neil Armstrong                            5   \n",
       "2  The Declaration of Independence                            5   \n",
       "3                  The Berlin Wall                            4   \n",
       "4                          Pompeii                            5   \n",
       "5                Winston Churchill                            5   \n",
       "6                      RMS Titanic                            4   \n",
       "7                The Mongol Empire                            5   \n",
       "8                          Slavery                            5   \n",
       "9        The Great Pyramid of Giza                            5   \n",
       "\n",
       "   outputs.relevance.gpt_relevance  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                4   \n",
       "4                                5   \n",
       "5                                5   \n",
       "6                                4   \n",
       "7                                5   \n",
       "8                                5   \n",
       "9                                5   \n",
       "\n",
       "                  outputs.relevance.relevance_reason  \\\n",
       "0  The response accurately and completely address...   \n",
       "1  The response accurately and completely answers...   \n",
       "2  The response fully addresses the query with ac...   \n",
       "3  The RESPONSE fully addresses the QUERY with ac...   \n",
       "4  The RESPONSE not only answers the QUERY accura...   \n",
       "5  The response accurately and completely answers...   \n",
       "6  The RESPONSE accurately and completely answers...   \n",
       "7  The response not only accurately and completel...   \n",
       "8  The response fully addresses the query with ac...   \n",
       "9  The RESPONSE fully addresses the QUERY with ac...   \n",
       "\n",
       "   outputs.coherence.coherence  outputs.coherence.gpt_coherence  \\\n",
       "0                            4                                4   \n",
       "1                            4                                4   \n",
       "2                            4                                4   \n",
       "3                            4                                4   \n",
       "4                            4                                4   \n",
       "5                            4                                4   \n",
       "6                            4                                4   \n",
       "7                            4                                4   \n",
       "8                            4                                4   \n",
       "9                            4                                4   \n",
       "\n",
       "                  outputs.coherence.coherence_reason  outputs.fluency.fluency  \\\n",
       "0  The RESPONSE is coherent and effectively addre...                        4   \n",
       "1  The response is coherent and directly addresse...                        4   \n",
       "2  The RESPONSE is coherent and effectively addre...                        4   \n",
       "3  The RESPONSE is coherent as it directly answer...                        3   \n",
       "4  The RESPONSE is coherent and effectively addre...                        3   \n",
       "5  The RESPONSE is coherent, directly answers the...                        4   \n",
       "6  The response is coherent because it directly a...                        3   \n",
       "7  The response is coherent and effectively addre...                        3   \n",
       "8  The RESPONSE is coherent and effectively addre...                        4   \n",
       "9  The RESPONSE is coherent and effectively addre...                        4   \n",
       "\n",
       "   outputs.fluency.gpt_fluency  \\\n",
       "0                            4   \n",
       "1                            4   \n",
       "2                            4   \n",
       "3                            3   \n",
       "4                            3   \n",
       "5                            4   \n",
       "6                            3   \n",
       "7                            3   \n",
       "8                            4   \n",
       "9                            4   \n",
       "\n",
       "                      outputs.fluency.fluency_reason  \\\n",
       "0  The RESPONSE demonstrates proficient fluency w...   \n",
       "1  The RESPONSE is well-articulated, with good co...   \n",
       "2  The RESPONSE should receive a high score becau...   \n",
       "3  The RESPONSE is clear and coherent with correc...   \n",
       "4  The RESPONSE is clear and coherent, with corre...   \n",
       "5  The response is well-articulated with good con...   \n",
       "6  The response is clear and grammatically correc...   \n",
       "7  The RESPONSE is clear and coherent, with corre...   \n",
       "8  The RESPONSE should receive a high score becau...   \n",
       "9  The RESPONSE is well-articulated with correct ...   \n",
       "\n",
       "   outputs.groundedness.groundedness  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                  5                                      5   \n",
       "1                                  5                                      5   \n",
       "2                                  5                                      5   \n",
       "3                                  5                                      5   \n",
       "4                                  5                                      5   \n",
       "5                                  5                                      5   \n",
       "6                                  5                                      5   \n",
       "7                                  5                                      5   \n",
       "8                                  5                                      5   \n",
       "9                                  5                                      5   \n",
       "\n",
       "            outputs.groundedness.groundedness_reason  \\\n",
       "0  The response accurately identifies the event a...   \n",
       "1  The response is fully correct and complete, di...   \n",
       "2  The RESPONSE is fully correct and complete, di...   \n",
       "3  The response is fully correct and complete, di...   \n",
       "4  The RESPONSE is fully correct and complete in ...   \n",
       "5  The response is fully correct and complete, di...   \n",
       "6  The response is fully correct and complete, di...   \n",
       "7  The response accurately and completely answers...   \n",
       "8  The response is fully grounded in the context,...   \n",
       "9  The response is fully correct and complete, di...   \n",
       "\n",
       "   outputs.helpfulness.helpfulness  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                5   \n",
       "4                                5   \n",
       "5                                5   \n",
       "6                                5   \n",
       "7                                5   \n",
       "8                                5   \n",
       "9                                5   \n",
       "\n",
       "              outputs.helpfulness.helpfulness_reason  line_number  \n",
       "0  The RESPONSE is fully helpful as it accurately...            0  \n",
       "1  The RESPONSE is fully helpful as it accurately...            1  \n",
       "2  The RESPONSE is entirely helpful as it fully a...            2  \n",
       "3  The RESPONSE is fully helpful as it accurately...            3  \n",
       "4  The RESPONSE is entirely helpful as it accurat...            4  \n",
       "5  The RESPONSE is fully helpful as it accurately...            5  \n",
       "6  The RESPONSE is fully helpful as it accurately...            6  \n",
       "7  The RESPONSE is entirely helpful as it accurat...            7  \n",
       "8  The RESPONSE is entirely helpful as it accurat...            8  \n",
       "9  The RESPONSE is entirely helpful as it accurat...            9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result[\"rows\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
