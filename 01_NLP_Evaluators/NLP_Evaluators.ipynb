{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-evaluation\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"RG_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"PROJECT_NAME\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NLP Evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BleuScoreEvaluator\n",
    "\n",
    "BLEU (Bilingual Evaluation Understudy) score is commonly used in natural language processing (NLP) and machine\n",
    "translation. It is widely used in text summarization and text generation use cases. It evaluates how closely the\n",
    "generated text matches the reference text. The BLEU score ranges from 0 to 1, with higher scores indicating\n",
    "better quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import BleuScoreEvaluator\n",
    "\n",
    "bleu = BleuScoreEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu_score': 0.22961813530951883}\n"
     ]
    }
   ],
   "source": [
    "result = bleu(response=\"Tokyo is the capital of Japan.\", ground_truth=\"The capital of Japan is Tokyo.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GleuScoreEvaluator\n",
    "\n",
    "The GLEU (Google-BLEU) score evaluator measures the similarity between generated and reference texts by\n",
    "evaluating n-gram overlap, considering both precision and recall. This balanced evaluation, designed for\n",
    "sentence-level assessment, makes it ideal for detailed analysis of translation quality. GLEU is well-suited for\n",
    "use cases such as machine translation, text summarization, and text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import GleuScoreEvaluator\n",
    "\n",
    "gleu = GleuScoreEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gleu_score': 0.4090909090909091}\n"
     ]
    }
   ],
   "source": [
    "result = gleu(response=\"Tokyo is the capital of Japan.\", ground_truth=\"The capital of Japan is Tokyo.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeteorScoreEvaluator\n",
    "\n",
    "The METEOR (Metric for Evaluation of Translation with Explicit Ordering) score grader evaluates generated text by\n",
    "comparing it to reference texts, focusing on precision, recall, and content alignment. It addresses limitations of\n",
    "other metrics like BLEU by considering synonyms, stemming, and paraphrasing. METEOR score considers synonyms and\n",
    "word stems to more accurately capture meaning and language variations. In addition to machine translation and\n",
    "text summarization, paraphrase detection is an optimal use case for the METEOR score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import MeteorScoreEvaluator\n",
    "\n",
    "meteor = MeteorScoreEvaluator(alpha=0.9, beta=3.0, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meteor_score': 0.9067055393586005}\n"
     ]
    }
   ],
   "source": [
    "result = meteor(response=\"Tokyo is the capital of Japan.\", ground_truth=\"The capital of Japan is Tokyo.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RougeScoreEvaluator\n",
    "\n",
    "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a set of metrics used to evaluate automatic\n",
    "summarization and machine translation. It measures the overlap between generated text and reference summaries.\n",
    "ROUGE focuses on recall-oriented measures to assess how well the generated text covers the reference text. Text\n",
    "summarization and document comparison are among optimal use cases for ROUGE, particularly in scenarios where text\n",
    "coherence and relevance are critical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import RougeScoreEvaluator, RougeType\n",
    "\n",
    "rouge = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_precision': 1.0, 'rouge_recall': 1.0, 'rouge_f1_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "result = rouge(response=\"Tokyo is the capital of Japan.\", ground_truth=\"The capital of Japan is Tokyo.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a Dataset using Math Evaluators\n",
    "\n",
    "The code below uses the Evaluate API with BLEU, GLEU, METEOR, and ROUGE evaluators to evaluate the results on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-25 09:43:26 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-02-25 09:43:26 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-02-25 09:43:26 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-02-25 09:43:26 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-02-25 09:43:26 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_e0lbxjvs_20250225_094325_444897, log path: C:\\Users\\alevret\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_e0lbxjvs_20250225_094325_444897\\logs.txt\n",
      "[2025-02-25 09:43:26 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_nc68mpg9_20250225_094325_441893, log path: C:\\Users\\alevret\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_nc68mpg9_20250225_094325_441893\\logs.txt\n",
      "[2025-02-25 09:43:26 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_nrlotud6_20250225_094325_443899, log path: C:\\Users\\alevret\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_nrlotud6_20250225_094325_443899\\logs.txt\n",
      "[2025-02-25 09:43:26 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_atxgm9sm_20250225_094325_442901, log path: C:\\Users\\alevret\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_atxgm9sm_20250225_094325_442901\\logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...Prompt flow service has started...\n",
      "\n",
      "Prompt flow service has started...\n",
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_atxgm9sm_20250225_094325_442901\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_nc68mpg9_20250225_094325_441893\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_nrlotud6_20250225_094325_443899\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_e0lbxjvs_20250225_094325_444897\n",
      "2025-02-25 09:43:26 +0000   35404 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-25 09:43:29 +0000   35404 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-02-25 09:43:29 +0000   35404 execution.bulk     INFO     Average execution time for completed lines: 0.06 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_nc68mpg9_20250225_094325_441893\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-25 09:43:25.435788+00:00\"\n",
      "Duration: \"0:00:06.379741\"\n",
      "Output path: \"C:\\Users\\alevret\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_nc68mpg9_20250225_094325_441893\"\n",
      "\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Average execution time for completed lines: 0.15 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Average execution time for completed lines: 0.15 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Average execution time for completed lines: 0.16 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-25 09:43:26 +0000   35404 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Average execution time for completed lines: 0.15 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_e0lbxjvs_20250225_094325_444897\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-25 09:43:25.437129+00:00\"\n",
      "Duration: \"0:00:09.522945\"\n",
      "Output path: \"C:\\Users\\alevret\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_e0lbxjvs_20250225_094325_444897\"\n",
      "\n",
      "2025-02-25 09:43:26 +0000   35404 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Average execution time for completed lines: 0.15 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_atxgm9sm_20250225_094325_442901\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-25 09:43:25.435788+00:00\"\n",
      "Duration: \"0:00:09.736947\"\n",
      "Output path: \"C:\\Users\\alevret\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_atxgm9sm_20250225_094325_442901\"\n",
      "\n",
      "2025-02-25 09:43:26 +0000   35404 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-02-25 09:43:33 +0000   35404 execution.bulk     INFO     Average execution time for completed lines: 0.16 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_nrlotud6_20250225_094325_443899\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-25 09:43:25.437129+00:00\"\n",
      "Duration: \"0:00:09.883954\"\n",
      "Output path: \"C:\\Users\\alevret\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_nrlotud6_20250225_094325_443899\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"bleu\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:09.522945\",\n",
      "        \"completed_lines\": 50,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"C:\\\\Users\\\\alevret\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_e0lbxjvs_20250225_094325_444897\"\n",
      "    },\n",
      "    \"gleu\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:09.736947\",\n",
      "        \"completed_lines\": 50,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"C:\\\\Users\\\\alevret\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_atxgm9sm_20250225_094325_442901\"\n",
      "    },\n",
      "    \"meteor\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:09.883954\",\n",
      "        \"completed_lines\": 50,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"C:\\\\Users\\\\alevret\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_nrlotud6_20250225_094325_443899\"\n",
      "    },\n",
      "    \"rouge\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:06.379741\",\n",
      "        \"completed_lines\": 50,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"C:\\\\Users\\\\alevret\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_nc68mpg9_20250225_094325_441893\"\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "\n",
    "result = evaluate(\n",
    "    data=\"data.jsonl\",\n",
    "    evaluators={\n",
    "        \"bleu\": bleu,\n",
    "        \"gleu\": gleu,\n",
    "        \"meteor\": meteor,\n",
    "        \"rouge\": rouge,\n",
    "    },\n",
    "    # Optionally provide your AI Studio project information to track your evaluation results in your Azure AI Studio project\n",
    "    azure_ai_project=azure_ai_project,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'bleu.bleu_score': 0.27254923738000003,\n",
      "             'gleu.gleu_score': 0.40707292707600007,\n",
      "             'meteor.meteor_score': 0.8376872508759999,\n",
      "             'rouge.rouge_f1_score': 0.6787035187120002,\n",
      "             'rouge.rouge_precision': 0.661285714288,\n",
      "             'rouge.rouge_recall': 0.7116190476240001},\n",
      " 'rows': [{'inputs.ground_truth': 'A dog is barking loudly.',\n",
      "           'inputs.response': 'The dog barks loudly.',\n",
      "           'line_number': 0,\n",
      "           'outputs.bleu.bleu_score': 0.1098261402,\n",
      "           'outputs.gleu.gleu_score': 0.2222222222,\n",
      "           'outputs.meteor.meteor_score': 0.6355932203,\n",
      "           'outputs.rouge.rouge_f1_score': 0.4444444444,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.4},\n",
      "          {'inputs.ground_truth': 'They visited the beach.',\n",
      "           'inputs.response': 'They went to the beach.',\n",
      "           'line_number': 1,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.7352941176000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The sun shines brightly.',\n",
      "           'inputs.response': 'The sun is shining brightly.',\n",
      "           'line_number': 2,\n",
      "           'outputs.bleu.bleu_score': 0.13742926600000002,\n",
      "           'outputs.gleu.gleu_score': 0.33333333330000003,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'She prepared a tasty meal.',\n",
      "           'inputs.response': 'She cooked a delicious meal.',\n",
      "           'line_number': 3,\n",
      "           'outputs.bleu.bleu_score': 0.1155637771,\n",
      "           'outputs.gleu.gleu_score': 0.2777777778,\n",
      "           'outputs.meteor.meteor_score': 0.5260416667,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.6000000000000001},\n",
      "          {'inputs.ground_truth': 'He reads the paper each morning.',\n",
      "           'inputs.response': 'He reads the newspaper every morning.',\n",
      "           'line_number': 4,\n",
      "           'outputs.bleu.bleu_score': 0.2427916178,\n",
      "           'outputs.gleu.gleu_score': 0.4090909091,\n",
      "           'outputs.meteor.meteor_score': 0.6914285714,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'Kids are playing in the park.',\n",
      "           'inputs.response': 'The children are playing in the park.',\n",
      "           'line_number': 5,\n",
      "           'outputs.bleu.bleu_score': 0.6803749333,\n",
      "           'outputs.gleu.gleu_score': 0.6923076923,\n",
      "           'outputs.meteor.meteor_score': 0.9844782984,\n",
      "           'outputs.rouge.rouge_f1_score': 0.7692307692,\n",
      "           'outputs.rouge.rouge_precision': 0.7142857143,\n",
      "           'outputs.rouge.rouge_recall': 0.8333333333},\n",
      "          {'inputs.ground_truth': 'The car is parked outside the house.',\n",
      "           'inputs.response': 'The car is parked outside.',\n",
      "           'line_number': 6,\n",
      "           'outputs.bleu.bleu_score': 0.5698363775,\n",
      "           'outputs.gleu.gleu_score': 0.5769230769,\n",
      "           'outputs.meteor.meteor_score': 0.7211538462,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8333333333,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_recall': 0.7142857143},\n",
      "          {'inputs.ground_truth': 'She writes a letter.',\n",
      "           'inputs.response': 'She is writing a letter.',\n",
      "           'line_number': 7,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'He watches a film.',\n",
      "           'inputs.response': 'He is watching a movie.',\n",
      "           'line_number': 8,\n",
      "           'outputs.bleu.bleu_score': 0.0494757029,\n",
      "           'outputs.gleu.gleu_score': 0.1666666667,\n",
      "           'outputs.meteor.meteor_score': 0.618872549,\n",
      "           'outputs.rouge.rouge_f1_score': 0.4444444444,\n",
      "           'outputs.rouge.rouge_precision': 0.4,\n",
      "           'outputs.rouge.rouge_recall': 0.5},\n",
      "          {'inputs.ground_truth': 'Flowers are in bloom.',\n",
      "           'inputs.response': 'The flowers are blooming.',\n",
      "           'line_number': 9,\n",
      "           'outputs.bleu.bleu_score': 0.054286939900000004,\n",
      "           'outputs.gleu.gleu_score': 0.1428571429,\n",
      "           'outputs.meteor.meteor_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.5},\n",
      "          {'inputs.ground_truth': 'They are enjoying a picnic.',\n",
      "           'inputs.response': 'They are having a picnic.',\n",
      "           'line_number': 10,\n",
      "           'outputs.bleu.bleu_score': 0.2939457035,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.8066666667,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8,\n",
      "           'outputs.rouge.rouge_precision': 0.8,\n",
      "           'outputs.rouge.rouge_recall': 0.8},\n",
      "          {'inputs.ground_truth': 'A baby is asleep.',\n",
      "           'inputs.response': 'The baby is sleeping.',\n",
      "           'line_number': 11,\n",
      "           'outputs.bleu.bleu_score': 0.1341419505,\n",
      "           'outputs.gleu.gleu_score': 0.2857142857,\n",
      "           'outputs.meteor.meteor_score': 0.5111111111000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.5},\n",
      "          {'inputs.ground_truth': 'She paints a picture.',\n",
      "           'inputs.response': 'She is painting a picture.',\n",
      "           'line_number': 12,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'He repairs the bike.',\n",
      "           'inputs.response': 'He is fixing the bike.',\n",
      "           'line_number': 13,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'A book is on the table.',\n",
      "           'inputs.response': 'The book is on the table.',\n",
      "           'line_number': 14,\n",
      "           'outputs.bleu.bleu_score': 0.8091067116,\n",
      "           'outputs.gleu.gleu_score': 0.8181818182,\n",
      "           'outputs.meteor.meteor_score': 0.8551587302,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8333333333,\n",
      "           'outputs.rouge.rouge_precision': 0.8333333333,\n",
      "           'outputs.rouge.rouge_recall': 0.8333333333},\n",
      "          {'inputs.ground_truth': 'They dance together.',\n",
      "           'inputs.response': 'They are dancing together.',\n",
      "           'line_number': 15,\n",
      "           'outputs.bleu.bleu_score': 0.1341419505,\n",
      "           'outputs.gleu.gleu_score': 0.2857142857,\n",
      "           'outputs.meteor.meteor_score': 0.9146341463000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'The coffee is very hot.',\n",
      "           'inputs.response': 'The coffee is hot.',\n",
      "           'line_number': 16,\n",
      "           'outputs.bleu.bleu_score': 0.30834517980000004,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.8203389831000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8888888889000001,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_recall': 0.8},\n",
      "          {'inputs.ground_truth': 'She learns to swim.',\n",
      "           'inputs.response': 'She is learning to swim.',\n",
      "           'line_number': 17,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'He plays the guitar.',\n",
      "           'inputs.response': 'He is playing the guitar.',\n",
      "           'line_number': 18,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The sky is clear and blue.',\n",
      "           'inputs.response': 'The sky is clear.',\n",
      "           'line_number': 19,\n",
      "           'outputs.bleu.bleu_score': 0.4739878501,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.7117647059000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'They build a sandcastle.',\n",
      "           'inputs.response': 'They are building a sandcastle.',\n",
      "           'line_number': 20,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The pizza is done.',\n",
      "           'inputs.response': 'The pizza is ready.',\n",
      "           'line_number': 21,\n",
      "           'outputs.bleu.bleu_score': 0.3218442408,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'She reads a novel.',\n",
      "           'inputs.response': 'She is reading a novel.',\n",
      "           'line_number': 22,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'He drives a car.',\n",
      "           'inputs.response': 'He is driving a car.',\n",
      "           'line_number': 23,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The water is chilly.',\n",
      "           'inputs.response': 'The water is cold.',\n",
      "           'line_number': 24,\n",
      "           'outputs.bleu.bleu_score': 0.3218442408,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'They sing a song.',\n",
      "           'inputs.response': 'They are singing a song.',\n",
      "           'line_number': 25,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The cake tastes great.',\n",
      "           'inputs.response': 'The cake is delicious.',\n",
      "           'line_number': 26,\n",
      "           'outputs.bleu.bleu_score': 0.1341419505,\n",
      "           'outputs.gleu.gleu_score': 0.2857142857,\n",
      "           'outputs.meteor.meteor_score': 0.5111111111000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.5},\n",
      "          {'inputs.ground_truth': 'She knits a scarf.',\n",
      "           'inputs.response': 'She is knitting a scarf.',\n",
      "           'line_number': 27,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'He jogs in the park.',\n",
      "           'inputs.response': 'He is jogging in the park.',\n",
      "           'line_number': 28,\n",
      "           'outputs.bleu.bleu_score': 0.4347208719,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.9653916211,\n",
      "           'outputs.rouge.rouge_f1_score': 0.7272727273,\n",
      "           'outputs.rouge.rouge_precision': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_recall': 0.8},\n",
      "          {'inputs.ground_truth': 'The room is tidy.',\n",
      "           'inputs.response': 'The room is clean.',\n",
      "           'line_number': 29,\n",
      "           'outputs.bleu.bleu_score': 0.3218442408,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'They watch the sunset.',\n",
      "           'inputs.response': 'They are watching the sunset.',\n",
      "           'line_number': 30,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The soup is steaming.',\n",
      "           'inputs.response': 'The soup is hot.',\n",
      "           'line_number': 31,\n",
      "           'outputs.bleu.bleu_score': 0.3218442408,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'She plants flowers.',\n",
      "           'inputs.response': 'She is planting flowers.',\n",
      "           'line_number': 32,\n",
      "           'outputs.bleu.bleu_score': 0.1341419505,\n",
      "           'outputs.gleu.gleu_score': 0.2857142857,\n",
      "           'outputs.meteor.meteor_score': 0.9146341463000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'He reads a magazine.',\n",
      "           'inputs.response': 'He is reading a magazine.',\n",
      "           'line_number': 33,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The ice cream melts.',\n",
      "           'inputs.response': 'The ice cream is melting.',\n",
      "           'line_number': 34,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'They play chess.',\n",
      "           'inputs.response': 'They are playing chess.',\n",
      "           'line_number': 35,\n",
      "           'outputs.bleu.bleu_score': 0.1341419505,\n",
      "           'outputs.gleu.gleu_score': 0.2857142857,\n",
      "           'outputs.meteor.meteor_score': 0.9146341463000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'The bread is freshly baked.',\n",
      "           'inputs.response': 'The bread is fresh.',\n",
      "           'line_number': 36,\n",
      "           'outputs.bleu.bleu_score': 0.2635037776,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.6355932203,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_recall': 0.6000000000000001},\n",
      "          {'inputs.ground_truth': 'She sews a dress.',\n",
      "           'inputs.response': 'She is sewing a dress.',\n",
      "           'line_number': 37,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'He fishes at the lake.',\n",
      "           'inputs.response': 'He is fishing at the lake.',\n",
      "           'line_number': 38,\n",
      "           'outputs.bleu.bleu_score': 0.4347208719,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.9653916211,\n",
      "           'outputs.rouge.rouge_f1_score': 0.7272727273,\n",
      "           'outputs.rouge.rouge_precision': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_recall': 0.8},\n",
      "          {'inputs.ground_truth': 'The tea is warm and soothing.',\n",
      "           'inputs.response': 'The tea is warm.',\n",
      "           'line_number': 39,\n",
      "           'outputs.bleu.bleu_score': 0.4739878501,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.7117647059000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'They hike in the mountains.',\n",
      "           'inputs.response': 'They are hiking in the mountains.',\n",
      "           'line_number': 40,\n",
      "           'outputs.bleu.bleu_score': 0.4347208719,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.9653916211,\n",
      "           'outputs.rouge.rouge_f1_score': 0.7272727273,\n",
      "           'outputs.rouge.rouge_precision': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_recall': 0.8},\n",
      "          {'inputs.ground_truth': 'The music is very loud.',\n",
      "           'inputs.response': 'The music is loud.',\n",
      "           'line_number': 41,\n",
      "           'outputs.bleu.bleu_score': 0.30834517980000004,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.8203389831000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8888888889000001,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_recall': 0.8},\n",
      "          {'inputs.ground_truth': 'She bakes cookies.',\n",
      "           'inputs.response': 'She is baking cookies.',\n",
      "           'line_number': 42,\n",
      "           'outputs.bleu.bleu_score': 0.1341419505,\n",
      "           'outputs.gleu.gleu_score': 0.2857142857,\n",
      "           'outputs.meteor.meteor_score': 0.9146341463000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'He plays basketball.',\n",
      "           'inputs.response': 'He is playing basketball.',\n",
      "           'line_number': 43,\n",
      "           'outputs.bleu.bleu_score': 0.1341419505,\n",
      "           'outputs.gleu.gleu_score': 0.2857142857,\n",
      "           'outputs.meteor.meteor_score': 0.9146341463000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'The wind is very strong.',\n",
      "           'inputs.response': 'The wind is strong.',\n",
      "           'line_number': 44,\n",
      "           'outputs.bleu.bleu_score': 0.30834517980000004,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.8203389831000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8888888889000001,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_recall': 0.8},\n",
      "          {'inputs.ground_truth': 'They study for exams.',\n",
      "           'inputs.response': 'They are studying for exams.',\n",
      "           'line_number': 45,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The film is interesting.',\n",
      "           'inputs.response': 'The movie is interesting.',\n",
      "           'line_number': 46,\n",
      "           'outputs.bleu.bleu_score': 0.3218442408,\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.meteor.meteor_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'She practices yoga.',\n",
      "           'inputs.response': 'She is practicing yoga.',\n",
      "           'line_number': 47,\n",
      "           'outputs.bleu.bleu_score': 0.1341419505,\n",
      "           'outputs.gleu.gleu_score': 0.2857142857,\n",
      "           'outputs.meteor.meteor_score': 0.9146341463000001,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666667000001},\n",
      "          {'inputs.ground_truth': 'He writes a report.',\n",
      "           'inputs.response': 'He is writing a report.',\n",
      "           'line_number': 48,\n",
      "           'outputs.bleu.bleu_score': 0.2511983594,\n",
      "           'outputs.gleu.gleu_score': 0.3888888889,\n",
      "           'outputs.meteor.meteor_score': 0.9490196078,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666667000001,\n",
      "           'outputs.rouge.rouge_precision': 0.6000000000000001,\n",
      "           'outputs.rouge.rouge_recall': 0.75},\n",
      "          {'inputs.ground_truth': 'The garden looks beautiful.',\n",
      "           'inputs.response': 'The garden is beautiful.',\n",
      "           'line_number': 49,\n",
      "           'outputs.bleu.bleu_score': 0.1714181485,\n",
      "           'outputs.gleu.gleu_score': 0.4285714286,\n",
      "           'outputs.meteor.meteor_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_recall': 0.75}],\n",
      " 'studio_url': 'https://ai.azure.com/build/evaluation/31ec42a0-48b1-4b0e-a040-390e65e1d0ac?wsid=/subscriptions/65a513ce-bb5d-4ed5-92b1-fa601d510a15/resourceGroups/agentai/providers/Microsoft.MachineLearningServices/workspaces/genaiops-demo'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
